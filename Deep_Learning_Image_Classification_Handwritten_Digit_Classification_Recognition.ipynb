{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning-Image Classification-Handwritten Digit Classification Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su2mwTWTNQVk",
        "colab_type": "text"
      },
      "source": [
        "#Machine Learning->Statistical Information or Formulas used to create model.\n",
        "#whereas,\n",
        "#Deep Learning->Artificial Neural Networks are used to create model\n",
        "###Everything else other than model creation is same in between ML mand DL, the main purpose being to predict anything from data after training the model, we get a function that can be used to predict anything."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEtP3Uc4Orsr",
        "colab_type": "text"
      },
      "source": [
        "###Regression is used for continuous data, whereas Classification is used to choose from different classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXPiDKM9PEEH",
        "colab_type": "text"
      },
      "source": [
        "#Artificial Neural Network(ANN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-41M_kHRld2",
        "colab_type": "text"
      },
      "source": [
        "###Images, sound clips and videos are highly non linear. \n",
        "###To increase the non-linearity we use activation functions like Sigmoid/relu/Softmax\n",
        "###Relu is the most popular and is mostly used activation function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZw1b1FDSO6A",
        "colab_type": "text"
      },
      "source": [
        "###All the inputs have a corresponding weight associated with it. \n",
        "###First part of neuron is to multiply the inputs of the previous neuron with weights i.e.,find a=x1w1 + x2w2+.....\n",
        "###Another task is Activation Function, that is used to increase the non-linearity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQhfcEYgTYZL",
        "colab_type": "text"
      },
      "source": [
        "###Deep Learning:\n",
        "###Forward Propagation\n",
        "###Back Propagation/Updation(As we update the weight here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWo3dPoCToW1",
        "colab_type": "text"
      },
      "source": [
        "###To deal with non linear data we have to increase non linearity in our data to make it more complex."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LGQasMpUrBP",
        "colab_type": "text"
      },
      "source": [
        "###Tensorflow is quite complex, so keras can be used as a high level option for it.\n",
        "###Tensorflow is a deep learning package/library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy7kjI-SVAP_",
        "colab_type": "text"
      },
      "source": [
        "###Colab gives us Free GPU->Graphic Processing Unit, GPU's are faster than CPU.\n",
        "###All the libraries are pre-installed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eJqKM-iVb9Z",
        "colab_type": "text"
      },
      "source": [
        "#Image Classification "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3-XNQYjVkI7",
        "colab_type": "text"
      },
      "source": [
        "###MNISTN is a very popular dataset for Image Classification.\n",
        "###It has 20X20 dataset.\n",
        "###Each image is a grey scale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2exodTeZV9Oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7okqHnQwWQyn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6d822ef9-4eaa-4ed6-9783-ce5935db5455"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUQ22GoWWlqb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a25953fd-f862-42fc-d62d-6271641f8cb4"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxFyBXqxW0QF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We have 60000 images in x_train of 28X28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4DeTfbfW_me",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8fd1a898-5143-40f3-c441-113b69e7ed67"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlXqqAa1XBbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#As it is a greyscale it reads only 28X28\n",
        "#In case of coloured or RGB(Red Green Blue) image it would have been 28X28X3, but the last part is ignored here as it is a black-white or greyscale image."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVhJgkkqXaYc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a838d9a-be64-403e-c622-f9deaccda912"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcWgZ8IhXcJD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61d14c78-acd9-4515-e573-36f819a4c728"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k0o3zMNXdca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#So is the case for y_train and y_test as it only contains the number for all the images in x_train and x_shape where as they themselve contains the images also."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8jQXY2HXwWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_img(img):\n",
        "    plt.imshow(img.reshape(28,28), cmap=\"gray\");#cmap is used for mapping scheme"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9ETc1luX88B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "38fac5e2-6839-42fe-fb5f-290b60ee2ad8"
      },
      "source": [
        "plot_img(x_train[1002])\n",
        "print(\"Image is : \", y_train[1002])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image is :  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAALWklEQVR4nO3dXYhc5R3H8d/PvHihXmwqXZcYGiu5KYXEEkKhIViDkubC6I0YpKRUWC8UFAptsBcKpRDa2l4KGwwmxfqCLxilVtMgTYsQskoSk1hNqgkmrAkmF4lXNvrvxZzIGnfObOacM2fS//cDw5x5ntk5fw755TlvM48jQgD+/13RdgEABoOwA0kQdiAJwg4kQdiBJOYOcmW2OfUPNCwiPFN7pZHd9hrb79s+Yntjlc8C0Cz3e53d9hxJH0i6VdJxSXskrY+IQyV/w8gONKyJkX2FpCMR8WFEfC7pGUnrKnwegAZVCftCSR9Pe328aPsa2+O2J21PVlgXgIoaP0EXEROSJiR244E2VRnZT0haNO319UUbgCFUJex7JC2xfYPt+ZLulrS9nrIA1K3v3fiIOG/7AUmvS5ojaUtEHKytMgC16vvSW18r45gdaFwjN9UAuHwQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5DEQKdsxuXn+eefL+0fGRkp7V+9enWd5aACRnYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSILr7Ch1++23l/Zv3rx5QJWgqkpht31U0jlJX0g6HxHL6ygKQP3qGNl/HBGf1vA5ABrEMTuQRNWwh6Q3bL9te3ymN9getz1pe7LiugBUUHU3fmVEnLD9bUk7bP87InZNf0NETEiakCTbUXF9APpUaWSPiBPF8ylJL0laUUdRAOrXd9htX2X7mgvLkm6TdKCuwgDUq8pu/Kikl2xf+Jy/RMTfaqkKQO36DntEfChpaY21AGgQl96AJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSfQMu+0ttk/ZPjCtbYHtHbYPF88jzZYJoKrZjOxPSlpzUdtGSTsjYomkncVrAEOsZ9gjYpekMxc1r5O0tVjeKumOmusCULO5ff7daERMFcufSBrt9kbb45LG+1wPgJr0G/avRETYjpL+CUkTklT2PgDN6vds/EnbY5JUPJ+qryQATeg37NslbSiWN0h6uZ5yADSl52687acl3SzpWtvHJT0iaZOk52zfK+mYpLuaLBLNueeee0r7584t/yeybdu2OstBg3qGPSLWd+laXXMtABrEHXRAEoQdSIKwA0kQdiAJwg4kUfkOOlze5s2bV9pvu7R/8eLFpf27d+++1JLQEEZ2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiC6+zJnT59urQ/ovzHhVatWlXa/+yzz15yTWgGIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMF19uReeeWV0v7z588PqBI0jZEdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASPcNue4vtU7YPTGt71PYJ23uLx9pmywRQ1WxG9iclrZmh/U8Rsax4/LXesgDUrWfYI2KXpDMDqAVAg6ocsz9ge3+xmz/S7U22x21P2p6ssC4AFfUb9scl3ShpmaQpSY91e2NETETE8ohY3ue6ANSgr7BHxMmI+CIivpS0WdKKessCULe+wm57bNrLOyUd6PZeAMOh5/fZbT8t6WZJ19o+LukRSTfbXiYpJB2VdF+DNWKIzZ8/v+0SMEs9wx4R62dofqKBWgA0iDvogCQIO5AEYQeSIOxAEoQdSMK9puStdWX24FaGWrz22mul/bfccktp/5VXXllnOZiFiPBM7YzsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEUzaj1EcffVTaP2fOnNL+pUuXdu3bt29fXzWhP4zsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE19lRyRVXlI8Xy5Yt69rHdfbBYmQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSS4zo5GnT17tu0SUOg5stteZPtN24dsH7T9YNG+wPYO24eL55HmywXQr9nsxp+X9IuI+J6kH0q63/b3JG2UtDMilkjaWbwGMKR6hj0ipiLinWL5nKT3JC2UtE7S1uJtWyXd0VSRAKq7pGN224sl3SRpt6TRiJgquj6RNNrlb8YljfdfIoA6zPpsvO2rJb0g6aGI+NpZl+jMDjnjpI0RMRERyyNieaVKAVQyq7DbnqdO0J+KiBeL5pO2x4r+MUmnmikRQB16Ttls2+ock5+JiIemtf9e0umI2GR7o6QFEfHLHp/FlM2XmWPHjpX2X3fddaX9TNk8eN2mbJ7NMfuPJP1U0ru29xZtD0vaJOk52/dKOibprjoKBdCMnmGPiH9JmvF/Ckmr6y0HQFO4XRZIgrADSRB2IAnCDiRB2IEk+IorSo2NjZX2v/XWWwOqBFUxsgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAElxnRyUHDx5suwTMEiM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTR83fja10ZvxsPNK7b78YzsgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEj3DbnuR7TdtH7J90PaDRfujtk/Y3ls81jZfLoB+9bypxvaYpLGIeMf2NZLelnSHOvOxfxYRf5j1yripBmhct5tqZjM/+5SkqWL5nO33JC2stzwATbukY3bbiyXdJGl30fSA7f22t9ge6fI347YnbU9WqhRAJbO+N9721ZL+Iem3EfGi7VFJn0oKSb9RZ1f/5z0+g914oGHdduNnFXbb8yS9Kun1iPjjDP2LJb0aEd/v8TmEHWhY31+EsW1JT0h6b3rQixN3F9wp6UDVIgE0ZzZn41dK+qekdyV9WTQ/LGm9pGXq7MYflXRfcTKv7LMY2YGGVdqNrwthB5rH99mB5Ag7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ9PzByZp9KunYtNfXFm3DaFhrG9a6JGrrV521fadbx0C/z/6NlduTEbG8tQJKDGttw1qXRG39GlRt7MYDSRB2IIm2wz7R8vrLDGttw1qXRG39GkhtrR6zAxictkd2AANC2IEkWgm77TW237d9xPbGNmroxvZR2+8W01C3Oj9dMYfeKdsHprUtsL3D9uHiecY59lqqbSim8S6ZZrzVbdf29OcDP2a3PUfSB5JulXRc0h5J6yPi0EAL6cL2UUnLI6L1GzBsr5L0maRtF6bWsv07SWciYlPxH+VIRPxqSGp7VJc4jXdDtXWbZvxnanHb1Tn9eT/aGNlXSDoSER9GxOeSnpG0roU6hl5E7JJ05qLmdZK2Fstb1fnHMnBdahsKETEVEe8Uy+ckXZhmvNVtV1LXQLQR9oWSPp72+riGa773kPSG7bdtj7ddzAxGp02z9Ymk0TaLmUHPabwH6aJpxodm2/Uz/XlVnKD7ppUR8QNJP5F0f7G7OpSicww2TNdOH5d0ozpzAE5JeqzNYoppxl+Q9FBEnJ3e1+a2m6GugWy3NsJ+QtKiaa+vL9qGQkScKJ5PSXpJncOOYXLywgy6xfOpluv5SkScjIgvIuJLSZvV4rYrphl/QdJTEfFi0dz6tpuprkFttzbCvkfSEts32J4v6W5J21uo4xtsX1WcOJHtqyTdpuGbinq7pA3F8gZJL7dYy9cMyzTe3aYZV8vbrvXpzyNi4A9Ja9U5I/8fSb9uo4YudX1X0r7icbDt2iQ9rc5u3X/VObdxr6RvSdop6bCkv0taMES1/Vmdqb33qxOssZZqW6nOLvp+SXuLx9q2t11JXQPZbtwuCyTBCTogCcIOJEHYgSQIO5AEYQeSIOxAEoQdSOJ/rQ2KBucbFEsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQmK9HpZY0uI",
        "colab_type": "text"
      },
      "source": [
        "#Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wyHzOfUY28m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create 5 layer Neural Network."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-Ts4wNXY87O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hyperparameter->the parameter that we have to define."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksj5ANyaZGkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Output layer no. of neurons = Unique classx_train[6878].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14obXd--ZnGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Input layer number of neurons = no. of features."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WSUyTVDZ_ZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2c44199-e971-46cb-8f12-e14468f85270"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGqLUhwnaVeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reshape the image to (1, 784)\n",
        "x_train = x_train.reshape(60000,784)\n",
        "x_test = x_test.reshape(10000,784)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDHRONTfalOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Flatenning the 28X28 image means one will follow the other 28 times both length and breadth wise.\n",
        "#ANN cannot handle data in 28X28 format it can only work with flattened data, so we need to reshape our whole data."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXSbw-2lbLlE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "90530506-ff6d-4520-9396-ff166b23cbbc"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvT6BBtLbjiz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7423cf1-0851-4b18-95ae-3c14df3d9a37"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7wrf9bnbnYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We are reshaping our data in order to get 2D data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c6V7hDBbsUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZQndfzgb4sq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(units=32, activation='relu', input_shape = (784,)))#adding the first hidden layer\n",
        "#Ignore the input layer in model.add()\n",
        "model.add(Dense(units=64, activation='relu'))#relu function is used to increase the non-linearity\n",
        "#We may not add the input_shape parameter in the next layer, as it knows from the first layer, but is must for the first layer\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=10, activation='softmax'))#final or the output layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXoseBAwdiP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To convert values into probability, we use softmax function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw46Q9zZeSEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "1d943905-17ac-4d4f-f454-e47cc9462c5d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 40,010\n",
            "Trainable params: 40,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7XvR-lneUUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])#if there were only two classes then use binary_crossentropy in loss, but in case of multiple class classification use categorical_crossentropy, so binary_crossentropy is a sunset of categorical_crossentropy\n",
        "#adam, sgd, rmsprop->algorithms that we can use in optimizer section\n",
        "#Param is the weights associated.\n",
        "#It is not possible to do back propagation without knowing the output, so we first need to do forward propagation."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqUWtUqvf0j4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcd882bb-5270-41bd-9397-bcf0f00c18f7"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMvvZGawf2tA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#One Hot Encoding is very important while doing multi-class classification\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hL47gG9mgPQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGhW81dZgVrT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q5RvkoMgZCA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f8b8529-b552-469c-d9f6-92866714ce9b"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvFY9c4Pgajs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75b67f74-1af7-4d69-8b27-e24cd02aa0c6"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqYTBqyIgcml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#10 represents the unique number of classes, or the number of neurons in the output layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8gMyFLIgsu9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "393afe13-a0ef-4fc2-ae7d-79c8004061a8"
      },
      "source": [
        "hist = model.fit(x = x_train, y= y_train, batch_size = 32, epochs = 10, validation_data=(x_test, y_test))\n",
        "#model training can be done in the above way"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.9391 - accuracy: 0.7805 - val_loss: 0.3845 - val_accuracy: 0.8975\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.3185 - accuracy: 0.9107 - val_loss: 0.2470 - val_accuracy: 0.9297\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.2428 - accuracy: 0.9312 - val_loss: 0.2295 - val_accuracy: 0.9356\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.2052 - accuracy: 0.9420 - val_loss: 0.2036 - val_accuracy: 0.9413\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1806 - accuracy: 0.9484 - val_loss: 0.1882 - val_accuracy: 0.9480\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1627 - accuracy: 0.9531 - val_loss: 0.1693 - val_accuracy: 0.9545\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1477 - accuracy: 0.9571 - val_loss: 0.1691 - val_accuracy: 0.9547\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1350 - accuracy: 0.9608 - val_loss: 0.1616 - val_accuracy: 0.9533\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1299 - accuracy: 0.9627 - val_loss: 0.1823 - val_accuracy: 0.9536\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1186 - accuracy: 0.9652 - val_loss: 0.1635 - val_accuracy: 0.9597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAmvyYQqhg5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loss is decreasing, and the accuracy and validation accuracy is increasing with every iteration, until it reaches a saturation\n",
        "#batch_size = 32 example in 1 iteration\n",
        "#epochs = 10 means 10 iterations(# of iterations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nLGHN8QiOZ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "570c0b69-d7cc-41c0-b978-abe4302ae430"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 23us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.16348506384557113, 0.9596999883651733]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ0eCrmdiRiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This means out of 10000 images 9600 images are being predicted correctly."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPjJLZ2Iigu6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7a22e9fe-8376-4b1b-9c74-97421c286082"
      },
      "source": [
        "plot_img(x_test[5001])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOSqelqEimJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict_classes(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlCni4zEjECi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04fa6686-0b70-4274-a141-da84707c1f46"
      },
      "source": [
        "y_pred[5001]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK89eQqLjMVO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8722b477-35c1-4b87-a2c6-3d533b50abd7"
      },
      "source": [
        "model.predict_classes(x_test[[5000]])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VumWRgrqjhuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Both the ways above can be used to predict the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgYdHX9Tjm2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Upload your own images and predict for that code:\n",
        "#this code is custom image."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xPt-6xQjx2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfzGL9rokDXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = image.load_img(\"name.png\", grayscale=True, target_size=(28,28))\n",
        "img = np.array(img)\n",
        "img = img.reshape(1,784)\n",
        "\n",
        "prediction = model.predict_classes(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7zMH-x-l9bU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}